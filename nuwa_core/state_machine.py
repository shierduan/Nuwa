"""
å‘é‡çŠ¶æ€æœºæ¨¡å— (Vector-Based State Machine Module)

åŠŸèƒ½ï¼šå°†æ–‡å­¦æè¿°è½¬åŒ–ä¸ºå¯è®¡ç®—çš„æ•°å­¦å‘é‡ï¼Œä½¿ç”¨å‘é‡ç®—æ³•è¿›è¡ŒçŠ¶æ€ç®¡ç†ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
- NarrativeState: è¯­ä¹‰åŒ–çš„çŠ¶æ€æ•°æ®ç»“æ„ï¼ˆå¢å¼ºç‰ˆï¼šåŒ…å«å‘é‡ï¼‰
- extract_semantic_state: ä»æ–‡æœ¬ä¸­æå–è¯­ä¹‰çŠ¶æ€ä¿¡æ¯
- update_vector_state: è®¡ç®—å¹¶æ›´æ–°çŠ¶æ€å‘é‡ï¼ˆä½¿ç”¨ EMA å¹³æ»‘ç®—æ³•ï¼‰
"""

import json
import re
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field, asdict
from datetime import datetime

# å¯¼å…¥å‘é‡è®¡ç®—ç›¸å…³åº“
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    np = None
    NUMPY_AVAILABLE = False

try:
    from sentence_transformers import SentenceTransformer
    EMBEDDING_AVAILABLE = True
except ImportError:
    SentenceTransformer = None
    EMBEDDING_AVAILABLE = False

from .model_utils import ensure_embedding_model_dir


@dataclass
class NarrativeState:
    """
    å™äº‹çŠ¶æ€å¯¹è±¡ï¼ˆè¯­ä¹‰åŒ– + å‘é‡åŒ–ï¼‰
    
    ä½¿ç”¨è¯­ä¹‰æè¿°è€Œéæ•°å­—ï¼Œæ›´ç¬¦åˆå°è¯´åˆ›ä½œé€»è¾‘ã€‚
    åŒæ—¶åŒ…å«å‘é‡è¡¨ç¤ºï¼Œç”¨äºæ•°å­¦è®¡ç®—å’Œç®—æ³•åˆ¤æ–­ã€‚
    """
    characters: Dict[str, Dict[str, Any]] = field(default_factory=dict)  # è§’è‰²çŠ¶æ€å­—å…¸
    relations: List[Dict[str, Any]] = field(default_factory=list)  # åŠ¨æ€ç¾ç»Šåˆ—è¡¨
    environment: str = ""  # ç¯å¢ƒæ°›å›´æè¿°
    plot_flags: List[str] = field(default_factory=list)  # å‰§æƒ…æ ‡å¿—åˆ—è¡¨
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    
    # å‘é‡è¡¨ç¤ºï¼ˆæ–°å¢ï¼‰
    character_vectors: Dict[str, List[float]] = field(default_factory=dict)  # è§’è‰²çŠ¶æ€å‘é‡
    # æ ¼å¼: { "äºšç‘Ÿ": [0.12, -0.5, ...] }  # 384ç»´å‘é‡ï¼ˆall-MiniLM-L6-v2ï¼‰
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        data = asdict(self)
        # å°† numpy æ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if NUMPY_AVAILABLE and np is not None:
            for char_name, vector in data.get("character_vectors", {}).items():
                if isinstance(vector, np.ndarray):
                    data["character_vectors"][char_name] = vector.tolist()
        return data
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²"""
        return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'NarrativeState':
        """ä»å­—å…¸åˆ›å»º NarrativeState"""
        return cls(**data)
    
    @classmethod
    def from_json(cls, json_str: str) -> 'NarrativeState':
        """ä» JSON å­—ç¬¦ä¸²åˆ›å»º NarrativeState"""
        return cls.from_dict(json.loads(json_str))


@dataclass
class ChapterNode:
    """
    ç« èŠ‚èŠ‚ç‚¹å¯¹è±¡ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼Œä½†ä½¿ç”¨ NarrativeStateï¼‰
    
    æ¯ä¸€ç« ä¸å†åªæ˜¯æ–‡æœ¬ï¼Œè€Œæ˜¯ä¸€ä¸ªèŠ‚ç‚¹å¯¹è±¡ï¼ŒåŒ…å«å®Œæ•´çš„çŠ¶æ€ä¿¡æ¯ã€‚
    """
    chapter_id: int
    text_content: str
    narrative_state: NarrativeState = field(default_factory=NarrativeState)  # è¯­ä¹‰åŒ–çŠ¶æ€
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    
    # NTD å‡çº§ï¼šçŠ¶æ€å‘é‡ï¼ˆæ–°å¢ï¼‰
    state_vector: Optional[List[float]] = None  # ç« èŠ‚æ•´ä½“çŠ¶æ€å‘é‡ï¼ˆ384ç»´ï¼‰
    # ç”± physique + psyche + environment æ‹¼æ¥åå‘é‡åŒ–å¾—åˆ°
    
    # å…¼å®¹æ—§ç‰ˆæœ¬çš„å­—æ®µï¼ˆä¿ç•™ä½†ä¸å†ä½¿ç”¨ï¼‰
    world_state: Dict[str, Any] = field(default_factory=dict)
    character_states: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        data = asdict(self)
        # å°† NarrativeState è½¬æ¢ä¸ºå­—å…¸
        data['narrative_state'] = self.narrative_state.to_dict()
        # å°† numpy æ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if NUMPY_AVAILABLE and np is not None and self.state_vector is not None:
            if isinstance(self.state_vector, np.ndarray):
                data['state_vector'] = self.state_vector.tolist()
        return data
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²"""
        return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ChapterNode':
        """ä»å­—å…¸åˆ›å»º ChapterNode"""
        # åˆ›å»ºæ•°æ®å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        node_data = data.copy()
        
        # å¤„ç† narrative_state
        if 'narrative_state' in node_data and isinstance(node_data['narrative_state'], dict):
            node_data['narrative_state'] = NarrativeState.from_dict(node_data['narrative_state'])
        elif 'narrative_state' not in node_data:
            # å¦‚æœæ²¡æœ‰ narrative_stateï¼Œå°è¯•ä»æ—§æ ¼å¼è½¬æ¢
            narrative_state = NarrativeState()
            
            # ä»æ—§æ ¼å¼çš„ world_state è½¬æ¢
            if 'world_state' in node_data:
                world_state = node_data.get('world_state', {})
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ è½¬æ¢é€»è¾‘ï¼Œå°† world_state è½¬æ¢ä¸º narrative_state çš„æ ¼å¼
            
            # ä»æ—§æ ¼å¼çš„ character_states è½¬æ¢
            if 'character_states' in node_data:
                character_states = node_data.get('character_states', {})
                for char_name, char_state in character_states.items():
                    # è½¬æ¢æ—§æ ¼å¼çš„è§’è‰²çŠ¶æ€
                    narrative_state.characters[char_name] = {
                        "physique": char_state.get("hp", ""),  # ç®€åŒ–è½¬æ¢
                        "psyche": char_state.get("emotion", ""),
                        "focus": "",
                        "equipment": char_state.get("items", []),
                    }
            
            # ä»æ—§æ ¼å¼çš„ plot_flags è½¬æ¢
            if 'plot_flags' in node_data:
                narrative_state.plot_flags = node_data.get('plot_flags', [])
            
            node_data['narrative_state'] = narrative_state
        
        # ç§»é™¤ä¸åœ¨ ChapterNode ä¸­çš„å­—æ®µï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
        valid_fields = {
            'chapter_id', 'text_content', 'narrative_state', 'timestamp', 
            'state_vector', 'world_state', 'character_states'
        }
        node_data = {k: v for k, v in node_data.items() if k in valid_fields}
        
        return cls(**node_data)
    
    @classmethod
    def from_json(cls, json_str: str) -> 'ChapterNode':
        """ä» JSON å­—ç¬¦ä¸²åˆ›å»º ChapterNode"""
        return cls.from_dict(json.loads(json_str))


def extract_semantic_state(
    text: str,
    prev_state: Optional[ChapterNode] = None,
    selected_model: str = "lm_studio",
    base_url: Optional[str] = None,
    model_name: Optional[str] = None,
    api_key: Optional[str] = None,
    gemini_base_url: Optional[str] = None,
    chapter_id: Optional[int] = None,
    characters: Optional[List[Dict[str, str]]] = None,
) -> ChapterNode:
    """
    è°ƒç”¨ LLM åˆ†ææ­£æ–‡ï¼Œæå–è¯­ä¹‰åŒ–çš„çŠ¶æ€ä¿¡æ¯
    
    Args:
        text: ç« èŠ‚æ­£æ–‡å†…å®¹
        prev_state: å‰ä¸€ç« çš„çŠ¶æ€èŠ‚ç‚¹ï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰
        selected_model: æ¨¡å‹ç±»å‹ ("lm_studio" æˆ– "gemini")
        base_url: LM Studio çš„ base_url
        model_name: æ¨¡å‹åç§°
        api_key: Gemini API Key
        gemini_base_url: Gemini çš„ base_url
        chapter_id: ç« èŠ‚ID
        characters: è§’è‰²åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"name": "è§’è‰²å", "description": "æè¿°"}, ...]
    
    Returns:
        ChapterNode: åŒ…å«æå–çš„è¯­ä¹‰çŠ¶æ€ä¿¡æ¯çš„ç« èŠ‚èŠ‚ç‚¹
    """
    if not text or len(text.strip()) < 10:
        # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œè¿”å›ç©ºçŠ¶æ€èŠ‚ç‚¹
        return ChapterNode(
            chapter_id=chapter_id or 0,
            text_content=text or "",
        )
    
    # æ„å»ºæå–çŠ¶æ€çš„æç¤ºè¯
    character_list_text = ""
    if characters:
        char_names = [char.get("name", "") for char in characters if char.get("name")]
        if char_names:
            character_list_text = f"\n\nã€è§’è‰²åˆ—è¡¨ã€‘\n{', '.join(char_names)}"
    
    prev_state_text = ""
    if prev_state and prev_state.narrative_state:
        prev_narrative = prev_state.narrative_state
        prev_state_text = f"""
ã€å‰ä¸€ç« çŠ¶æ€å¿«ç…§ã€‘
- è§’è‰²çŠ¶æ€ï¼š{json.dumps(prev_narrative.characters, ensure_ascii=False)[:800]}
- å…³ç³»çŠ¶æ€ï¼š{json.dumps(prev_narrative.relations, ensure_ascii=False)[:500]}
- ç¯å¢ƒæ°›å›´ï¼š{prev_narrative.environment[:200]}
- å‰§æƒ…æ ‡å¿—ï¼š{', '.join(prev_narrative.plot_flags[:10])}
"""
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´çŠ¶æ€åˆ†æå™¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç« èŠ‚æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–çš„è¯­ä¹‰çŠ¶æ€ä¿¡æ¯ã€‚

**é‡è¦è¦æ±‚ï¼šä¸è¦è¾“å‡ºæ•°å­—ã€‚è¯·ç”¨ç²¾ç‚¼çš„æ–‡å­¦è¯­è¨€æè¿°è§’è‰²çš„å½“å‰çŠ¶æ€ã€‚é‡ç‚¹æå–é‚£äº›ä¼šå½±å“ä¸‹ä¸€ç« å‰§æƒ…èµ°å‘çš„è¦ç´ ï¼ˆå¦‚ä¼¤åŠ¿ã€æƒ…ç»ªã€æŒæœ‰çš„å…³é”®ç‰©å“ï¼‰ã€‚**

æå–è¦æ±‚ï¼š
1. **è§’è‰²çŠ¶æ€ (characters)**ï¼šå¯¹æ¯ä¸ªå‡ºç°çš„è§’è‰²ï¼Œæå–ï¼š
   - physique: ç”Ÿç†çŠ¶æ€æè¿°ï¼ˆå¦‚ï¼š"å·¦è‡‚è´¯ç©¿ä¼¤ï¼Œä½“åŠ›é€æ”¯ï¼Œæ¿’ä¸´æ˜è¿·"ï¼‰- ä»£æ›¿ HP
   - psyche: å¿ƒç†çŠ¶æ€æè¿°ï¼ˆå¦‚ï¼š"å› èƒŒå›è€Œæåº¦æ„¤æ¨ï¼Œç†æ™ºçº¿ç´§ç»·"ï¼‰- ä»£æ›¿ SAN/Mood
     **å¿ƒç†çŠ¶æ€æå–çº¦æŸ**ï¼š
     * å¿…é¡»åŸºäºæ­£æ–‡ä¸­è¯¥è§’è‰²çš„å®é™…è¡¨ç°å’Œå†…å¿ƒæ´»åŠ¨
     * å¿…é¡»ä¸å‰ä¸€ç« çš„å¿ƒç†çŠ¶æ€æœ‰é€»è¾‘è¿è´¯æ€§ï¼ˆé™¤éæ­£æ–‡æ˜ç¡®æè¿°äº†æƒ…ç»ªçªå˜ï¼‰
     * å¿…é¡»ä¸è§’è‰²çš„æ€§æ ¼è®¾å®šç›¸ç¬¦ï¼ˆå‚è€ƒè§’è‰²åˆ—è¡¨ä¸­çš„æè¿°ï¼‰
     * ä¸è¦æå–å…¶ä»–è§’è‰²çš„å¿ƒç†çŠ¶æ€
     * ä¸è¦æå–è¿‡äºç¬¼ç»Ÿçš„æè¿°ï¼ˆå¦‚"æ­£å¸¸"ã€"ä¸€èˆ¬"ï¼‰ï¼Œè¦å…·ä½“ï¼ˆå¦‚"å› ç´§å¼ è€Œæ‰‹å¿ƒå‡ºæ±—"ï¼‰
     * ä¸è¦æå–æ­£æ–‡ä¸­æ²¡æœ‰ä½“ç°çš„å¿ƒç†çŠ¶æ€
   - focus: å½“å‰è¡ŒåŠ¨å…ƒï¼ˆAction Driverï¼Œå¦‚ï¼š"å¿…é¡»åœ¨æ—¥è½å‰æŠŠä¿¡é€å‡º"ï¼‰
   - equipment: å…³é”®é“å…·åˆ—è¡¨ï¼ˆä»…è®°å½•å‰§æƒ…ç›¸å…³çš„ï¼Œå¦‚ï¼š["æ–­è£‚çš„å®¶å¾½å‰‘", "æ²¾è¡€çš„ä¿¡"]ï¼‰

2. **å…³ç³»çŠ¶æ€ (relations)**ï¼šè§’è‰²é—´çš„åŠ¨æ€ç¾ç»Š
   - target: ç›®æ ‡è§’è‰²å
   - status: å…³ç³»çŠ¶æ€ï¼ˆå¦‚ï¼š"å†³è£‚"ã€"ç»“ç›Ÿ"ã€"æš—æ‹"ç­‰ï¼‰
   - tone: å…³ç³»æ°›å›´ï¼ˆå¦‚ï¼š"å‰‘æ‹”å¼©å¼ "ã€"æ¸©æƒ…è„‰è„‰"ç­‰ï¼‰

3. **ç¯å¢ƒæ°›å›´ (environment)**ï¼šå½“å‰åœºæ™¯çš„ç¯å¢ƒæè¿°ï¼ˆå¦‚ï¼š"æš´é›¨ä¸­çš„æ³¥æ³å°é“ï¼Œèƒ½è§åº¦æä½"ï¼‰

4. **å‰§æƒ…æ ‡å¿— (plot_flags)**ï¼šé‡è¦å‰§æƒ…äº‹ä»¶ï¼ˆå¦‚ï¼š"åæ´¾å·²æ­»"ã€"è·å¾—ç¥å™¨"ã€"å‘ç°çœŸç›¸"ç­‰ï¼‰

è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ä¸¥æ ¼çš„ JSONï¼ŒåŒ…å«ä»¥ä¸‹ç»“æ„ï¼š
{
  "characters": {
    "è§’è‰²å1": {
      "physique": "ç”Ÿç†çŠ¶æ€æè¿°",
      "psyche": "å¿ƒç†çŠ¶æ€æè¿°",
      "focus": "å½“å‰è¡ŒåŠ¨å…ƒ",
      "equipment": ["é“å…·1", "é“å…·2"]
    },
    "è§’è‰²å2": {
      ...
    }
  },
  "relations": [
    {
      "target": "ç›®æ ‡è§’è‰²å",
      "status": "å…³ç³»çŠ¶æ€",
      "tone": "å…³ç³»æ°›å›´"
    }
  ],
  "environment": "ç¯å¢ƒæ°›å›´æè¿°",
  "plot_flags": ["å‰§æƒ…æ ‡å¿—1", "å‰§æƒ…æ ‡å¿—2"]
}

å¦‚æœæŸä¸ªç»´åº¦æ²¡æœ‰ä¿¡æ¯ï¼Œä½¿ç”¨ç©ºå¯¹è±¡ {} æˆ–ç©ºæ•°ç»„ []ã€‚"""

    user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç« èŠ‚æ–‡æœ¬ï¼Œæå–è¯­ä¹‰çŠ¶æ€ä¿¡æ¯ã€‚{character_list_text}{prev_state_text}

ã€ç« èŠ‚æ–‡æœ¬ã€‘
{text[:3000]}

è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚é‡ç‚¹æ˜¯ç”¨æ–‡å­¦è¯­è¨€æè¿°çŠ¶æ€ï¼Œä¸è¦ä½¿ç”¨æ•°å­—ã€‚"""

    # è°ƒç”¨ LLMï¼ˆåªä½¿ç”¨å·²åŠ è½½çš„æ¨¡å—ï¼Œé¿å…è§¦å‘ Streamlit UI ä»£ç æ‰§è¡Œï¼‰
    result_text = None
    
    try:
        import sys
        
        # åªä»å·²åŠ è½½çš„æ¨¡å—ä¸­è·å–å‡½æ•°ï¼Œç»ä¸å°è¯•å¯¼å…¥ï¼ˆé¿å…è§¦å‘ UI ä»£ç ï¼‰
        generate_content_lm_studio = None
        generate_content_gemini = None
        
        # åœ¨ Streamlit ä¸­ï¼Œä¸»æ–‡ä»¶å¯èƒ½ä»¥ '__main__' è¿è¡Œï¼Œä¹Ÿå¯èƒ½ä»¥ 'app' è¿è¡Œ
        # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„æ¨¡å—åä¸­è·å–å‡½æ•°
        possible_module_names = ['app', '__main__']
        
        for module_name in possible_module_names:
            if module_name in sys.modules:
                module = sys.modules[module_name]
                if generate_content_lm_studio is None:
                    generate_content_lm_studio = getattr(module, 'generate_content_lm_studio', None)
                if generate_content_gemini is None:
                    generate_content_gemini = getattr(module, 'generate_content_gemini', None)
                
                # å¦‚æœä¸¤ä¸ªå‡½æ•°éƒ½æ‰¾åˆ°äº†ï¼Œå¯ä»¥æå‰é€€å‡º
                if generate_content_lm_studio is not None and generate_content_gemini is not None:
                    break
        
        # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•ä»æ‰€æœ‰å·²åŠ è½½çš„æ¨¡å—ä¸­æœç´¢ï¼ˆä½†è·³è¿‡å†…ç½®æ¨¡å—ï¼‰
        if generate_content_lm_studio is None or generate_content_gemini is None:
            for module_name, module in sys.modules.items():
                if module is None:
                    continue
                # è·³è¿‡å†…ç½®æ¨¡å—å’Œæ ‡å‡†åº“
                if module_name.startswith('_') or '.' in module_name:
                    continue
                
                if generate_content_lm_studio is None:
                    generate_content_lm_studio = getattr(module, 'generate_content_lm_studio', None)
                if generate_content_gemini is None:
                    generate_content_gemini = getattr(module, 'generate_content_gemini', None)
                
                if generate_content_lm_studio is not None and generate_content_gemini is not None:
                    break
        
        if generate_content_lm_studio is None or generate_content_gemini is None:
            # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            loaded_modules = [name for name in sys.modules.keys() if not name.startswith('_') and '.' not in name]
            raise ImportError(
                f"æ— æ³•è·å–ç”Ÿæˆå‡½æ•°ã€‚å·²æ£€æŸ¥çš„æ¨¡å—: {possible_module_names}ã€‚"
                f"å·²åŠ è½½çš„æ¨¡å—ï¼ˆéƒ¨åˆ†ï¼‰: {loaded_modules[:10]}ã€‚"
                "è¯·ç¡®ä¿ app æ¨¡å—å·²åŠ è½½ã€‚"
                "æ³¨æ„ï¼šnuwa_core ä¸èƒ½å¯¼å…¥ app æ¨¡å—ï¼Œå› ä¸ºä¼šå¯¼è‡´ Streamlit UI ä»£ç é‡å¤æ‰§è¡Œã€‚"
            )
        
        if selected_model == "gemini":
            if not api_key or not model_name:
                raise ValueError("Gemini é…ç½®ä¸å®Œæ•´")
            
            success, result = generate_content_gemini(
                api_key=api_key,
                model_name=model_name,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                base_url=gemini_base_url,
                max_output_tokens=2048,
                temperature=0.3,
                stream=False,
            )
            if success:
                result_text = result
        else:
            # LM Studio
            if not base_url or not model_name:
                raise ValueError("LM Studio é…ç½®ä¸å®Œæ•´")
            
            success, result = generate_content_lm_studio(
                base_url=base_url,
                model_name=model_name,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                max_tokens=2048,
                temperature=0.3,
                stream=False,
            )
            if success:
                result_text = result
    except Exception as e:
        print(f"çŠ¶æ€æå–å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        result_text = None
    
    # è§£æç»“æœ
    if not result_text:
        # å¦‚æœ LLM è°ƒç”¨å¤±è´¥ï¼Œè¿”å›åŸºç¡€èŠ‚ç‚¹
        return ChapterNode(
            chapter_id=chapter_id or 0,
            text_content=text,
        )
    
    # å°è¯•æå– JSON
    state_data = _parse_state_json(result_text)
    
    # åˆå¹¶å‰ä¸€ç« çš„çŠ¶æ€ï¼ˆå¢é‡æ›´æ–°ï¼‰
    if prev_state and prev_state.narrative_state:
        state_data = _merge_semantic_states(prev_state.narrative_state, state_data)
    
    # éªŒè¯å’Œä¿®æ­£å¿ƒç†çŠ¶æ€ï¼ˆæ·»åŠ çº¦æŸæ£€æŸ¥ï¼‰
    if characters:
        state_data = _validate_and_correct_psyche(
            state_data=state_data,
            text=text,
            prev_state=prev_state,
            characters=characters,
            selected_model=selected_model,
            base_url=base_url,
            model_name=model_name,
            api_key=api_key,
            gemini_base_url=gemini_base_url,
        )
    
    # åˆ›å»º NarrativeState
    narrative_state = NarrativeState(
        characters=state_data.get("characters", {}),
        relations=state_data.get("relations", []),
        environment=state_data.get("environment", ""),
        plot_flags=state_data.get("plot_flags", []),
    )
    
    # è®¡ç®—å¹¶æ›´æ–°å‘é‡çŠ¶æ€ï¼ˆä½¿ç”¨ EMA å¹³æ»‘ï¼‰
    prev_narrative_state = prev_state.narrative_state if prev_state else None
    narrative_state = update_vector_state(
        narrative_state=narrative_state,
        prev_narrative_state=prev_narrative_state,
        alpha=0.7  # EMA å¹³æ»‘ç³»æ•°ï¼ˆå¯è°ƒï¼‰
    )
    
    # ==================== NTD å‡çº§ï¼šè®¡ç®—ç« èŠ‚æ•´ä½“çŠ¶æ€å‘é‡ ====================
    # å°† physique + psyche + environment æ‹¼æ¥æˆæè¿°æ–‡æœ¬ï¼Œç„¶åå‘é‡åŒ–
    state_vector = _compute_chapter_state_vector(
        narrative_state=narrative_state,
        prev_state=prev_state,
        alpha=0.7  # EMA å¹³æ»‘ç³»æ•°
    )
    
    # åˆ›å»º ChapterNode
    return ChapterNode(
        chapter_id=chapter_id or 0,
        text_content=text,
        narrative_state=narrative_state,
        state_vector=state_vector,  # æ–°å¢ï¼šç« èŠ‚çŠ¶æ€å‘é‡
    )


# å…¼å®¹æ—§ç‰ˆæœ¬çš„å‡½æ•°å
def extract_state(
    text: str,
    prev_state: Optional[ChapterNode] = None,
    selected_model: str = "lm_studio",
    base_url: Optional[str] = None,
    model_name: Optional[str] = None,
    api_key: Optional[str] = None,
    gemini_base_url: Optional[str] = None,
    chapter_id: Optional[int] = None,
    characters: Optional[List[Dict[str, str]]] = None,
) -> ChapterNode:
    """
    å…¼å®¹æ—§ç‰ˆæœ¬çš„å‡½æ•°åï¼Œå®é™…è°ƒç”¨ extract_semantic_state
    """
    return extract_semantic_state(
        text=text,
        prev_state=prev_state,
        selected_model=selected_model,
        base_url=base_url,
        model_name=model_name,
        api_key=api_key,
        gemini_base_url=gemini_base_url,
        chapter_id=chapter_id,
        characters=characters,
    )


def _parse_state_json(text: str) -> Dict[str, Any]:
    """
    ä» LLM è¾“å‡ºä¸­è§£æ JSON çŠ¶æ€æ•°æ®
    
    Args:
        text: LLM è¿”å›çš„æ–‡æœ¬
    
    Returns:
        è§£æåçš„çŠ¶æ€æ•°æ®å­—å…¸
    """
    if not text:
        return {}
    
    # å°è¯•æå– JSON ä»£ç å—
    json_match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
    if json_match:
        json_str = json_match.group(1)
    else:
        # å°è¯•ç›´æ¥æå–ç¬¬ä¸€ä¸ª JSON å¯¹è±¡
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
        else:
            return {}
    
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜
        try:
            # ç§»é™¤æ³¨é‡Š
            json_str = re.sub(r'//.*?\n', '\n', json_str)
            json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
            return json.loads(json_str)
        except Exception:
            return {}


def _merge_semantic_states(prev_state: NarrativeState, new_state: Dict[str, Any]) -> Dict[str, Any]:
    """
    åˆå¹¶å‰ä¸€ç« çš„è¯­ä¹‰çŠ¶æ€å’Œæ–°æå–çš„çŠ¶æ€ï¼ˆå¢é‡æ›´æ–°ï¼‰
    
    Args:
        prev_state: å‰ä¸€ç« çš„è¯­ä¹‰çŠ¶æ€
        new_state: æ–°æå–çš„çŠ¶æ€æ•°æ®
    
    Returns:
        åˆå¹¶åçš„çŠ¶æ€æ•°æ®
    """
    merged = {
        "characters": {k: v.copy() for k, v in prev_state.characters.items()},
        "relations": prev_state.relations.copy(),
        "environment": prev_state.environment,
        "plot_flags": prev_state.plot_flags.copy(),
    }
    
    # æ›´æ–°è§’è‰²çŠ¶æ€ï¼ˆå¢é‡æ›´æ–°ï¼‰
    if "characters" in new_state:
        for char_name, char_state in new_state["characters"].items():
            if char_name in merged["characters"]:
                # åˆå¹¶ç°æœ‰çŠ¶æ€ï¼ˆæ–°çŠ¶æ€è¦†ç›–æ—§çŠ¶æ€ï¼‰
                merged["characters"][char_name].update(char_state)
            else:
                # æ–°å¢è§’è‰²çŠ¶æ€
                merged["characters"][char_name] = char_state
    
    # æ›´æ–°å…³ç³»çŠ¶æ€ï¼ˆè¿½åŠ æ–°å…³ç³»ï¼Œå»é‡ï¼‰
    if "relations" in new_state:
        for new_rel in new_state["relations"]:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„å…³ç³»
            exists = False
            for existing_rel in merged["relations"]:
                if (existing_rel.get("target") == new_rel.get("target") and
                    existing_rel.get("status") == new_rel.get("status")):
                    # æ›´æ–°ç°æœ‰å…³ç³»
                    existing_rel.update(new_rel)
                    exists = True
                    break
            if not exists:
                merged["relations"].append(new_rel)
    
    # æ›´æ–°ç¯å¢ƒæ°›å›´ï¼ˆæ–°ç¯å¢ƒè¦†ç›–æ—§ç¯å¢ƒï¼‰
    if "environment" in new_state and new_state["environment"]:
        merged["environment"] = new_state["environment"]
    
    # æ›´æ–°å‰§æƒ…æ ‡å¿—ï¼ˆå»é‡ï¼‰
    if "plot_flags" in new_state:
        for flag in new_state["plot_flags"]:
            if flag not in merged["plot_flags"]:
                merged["plot_flags"].append(flag)
    
    return merged


def _validate_and_correct_psyche(
    state_data: Dict[str, Any],
    text: str,
    prev_state: Optional[ChapterNode],
    characters: List[Dict[str, str]],
    selected_model: str,
    base_url: Optional[str],
    model_name: Optional[str],
    api_key: Optional[str],
    gemini_base_url: Optional[str],
) -> Dict[str, Any]:
    """
    éªŒè¯å’Œä¿®æ­£å¿ƒç†çŠ¶æ€æå–ç»“æœ
    
    æ£€æŸ¥å¿ƒç†çŠ¶æ€æ˜¯å¦ï¼š
    1. ä¸æ­£æ–‡å†…å®¹åŒ¹é…
    2. ä¸å‰ä¸€ç« çŠ¶æ€è¿è´¯
    3. ä¸è§’è‰²è®¾å®šä¸€è‡´
    
    Args:
        state_data: æå–çš„çŠ¶æ€æ•°æ®
        text: ç« èŠ‚æ­£æ–‡
        prev_state: å‰ä¸€ç« çŠ¶æ€
        characters: è§’è‰²åˆ—è¡¨
        selected_model: æ¨¡å‹ç±»å‹
        base_url: LM Studio base_url
        model_name: æ¨¡å‹åç§°
        api_key: Gemini API Key
        gemini_base_url: Gemini base_url
    
    Returns:
        ä¿®æ­£åçš„çŠ¶æ€æ•°æ®
    """
    if "characters" not in state_data:
        return state_data
    
    # æ„å»ºè§’è‰²è®¾å®šå­—å…¸
    character_profiles = {}
    for char in characters:
        char_name = char.get("name", "")
        if char_name:
            character_profiles[char_name] = char.get("description", "")
    
    # æ„å»ºå‰ä¸€ç« å¿ƒç†çŠ¶æ€å­—å…¸
    prev_psyche = {}
    if prev_state and prev_state.narrative_state:
        for char_name, char_state in prev_state.narrative_state.characters.items():
            prev_psyche[char_name] = char_state.get("psyche", "")
    
    # å¯¹æ¯ä¸ªè§’è‰²çš„å¿ƒç†çŠ¶æ€è¿›è¡ŒéªŒè¯
    for char_name, char_state in state_data["characters"].items():
        current_psyche = char_state.get("psyche", "").strip()
        
        # å¦‚æœå¿ƒç†çŠ¶æ€ä¸ºç©ºï¼Œè·³è¿‡éªŒè¯
        if not current_psyche:
            continue
        
        # æ£€æŸ¥1: å¿ƒç†çŠ¶æ€æ˜¯å¦ä¸æ­£æ–‡å†…å®¹åŒ¹é…
        if not _verify_psyche_matches_text(char_name, current_psyche, text):
            # å¦‚æœéªŒè¯å¤±è´¥ï¼Œå°è¯•ä»æ­£æ–‡ä¸­é‡æ–°æå–
            corrected_psyche = _re_extract_psyche_from_text(
                char_name=char_name,
                text=text,
                prev_psyche=prev_psyche.get(char_name, ""),
                character_profile=character_profiles.get(char_name, ""),
                selected_model=selected_model,
                base_url=base_url,
                model_name=model_name,
                api_key=api_key,
                gemini_base_url=gemini_base_url,
            )
            if corrected_psyche:
                char_state["psyche"] = corrected_psyche
                print(f"âš ï¸ ä¿®æ­£è§’è‰²ã€Œ{char_name}ã€çš„å¿ƒç†çŠ¶æ€ï¼š{current_psyche} â†’ {corrected_psyche}")
        
        # æ£€æŸ¥2: å¿ƒç†çŠ¶æ€æ˜¯å¦ä¸å‰ä¸€ç« è¿è´¯ï¼ˆé™¤éæ­£æ–‡æ˜ç¡®æè¿°æƒ…ç»ªçªå˜ï¼‰
        if char_name in prev_psyche and prev_psyche[char_name]:
            if not _verify_psyche_continuity(
                char_name=char_name,
                current_psyche=current_psyche,
                prev_psyche=prev_psyche[char_name],
                text=text,
            ):
                # å¦‚æœè¿è´¯æ€§æ£€æŸ¥å¤±è´¥ï¼Œä¿ç•™å½“å‰çŠ¶æ€ä½†è®°å½•è­¦å‘Š
                print(f"âš ï¸ è§’è‰²ã€Œ{char_name}ã€çš„å¿ƒç†çŠ¶æ€å¯èƒ½ä¸å‰ç« ä¸è¿è´¯ï¼š{prev_psyche[char_name]} â†’ {current_psyche}")
    
    return state_data


def _verify_psyche_matches_text(char_name: str, psyche: str, text: str) -> bool:
    """
    éªŒè¯å¿ƒç†çŠ¶æ€æ˜¯å¦ä¸æ­£æ–‡å†…å®¹åŒ¹é…
    
    Args:
        char_name: è§’è‰²å
        psyche: å¿ƒç†çŠ¶æ€æè¿°
        text: æ­£æ–‡å†…å®¹
    
    Returns:
        æ˜¯å¦åŒ¹é…
    """
    if not psyche or not text:
        return True  # å¦‚æœä¸ºç©ºï¼Œè®¤ä¸ºåŒ¹é…ï¼ˆé¿å…è¯¯åˆ¤ï¼‰
    
    # ç®€å•çš„å…³é”®è¯åŒ¹é…æ£€æŸ¥
    # å¦‚æœå¿ƒç†çŠ¶æ€ä¸­çš„å…³é”®è¯åœ¨æ­£æ–‡ä¸­æ‰¾ä¸åˆ°ï¼Œå¯èƒ½ä¸åŒ¹é…
    psyche_keywords = ["æ„¤æ€’", "ææƒ§", "ç´§å¼ ", "å…´å¥‹", "æ‚²ä¼¤", "å¿«ä¹", "ç„¦è™‘", "å¹³é™", "å›°æƒ‘", "åšå®š"]
    found_keywords = [kw for kw in psyche_keywords if kw in psyche]
    
    if found_keywords:
        # æ£€æŸ¥è¿™äº›å…³é”®è¯æ˜¯å¦åœ¨è§’è‰²ç›¸å…³çš„æ–‡æœ¬ä¸­å‡ºç°
        # ç®€å•æ£€æŸ¥ï¼šå¦‚æœæ­£æ–‡ä¸­åŒ…å«è§’è‰²åï¼Œä¸”åŒ…å«ç›¸å…³æƒ…ç»ªè¯æ±‡ï¼Œè®¤ä¸ºåŒ¹é…
        if char_name in text:
            # æ£€æŸ¥æ­£æ–‡ä¸­æ˜¯å¦æœ‰æƒ…ç»ªç›¸å…³çš„æè¿°
            text_lower = text.lower()
            for keyword in found_keywords:
                if keyword in text_lower:
                    return True
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…³é”®è¯ï¼Œä½†å¿ƒç†çŠ¶æ€æè¿°è¾ƒé•¿ï¼Œå¯èƒ½æ˜¯åˆç†çš„ï¼ˆLLM å¯èƒ½ç”¨ä¸åŒè¯æ±‡è¡¨è¾¾ï¼‰
            if len(psyche) > 10:
                return True  # è¾ƒé•¿çš„æè¿°å¯èƒ½æ˜¯åˆç†çš„æ¦‚æ‹¬
    
    # å¦‚æœå¿ƒç†çŠ¶æ€å¾ˆçŸ­æˆ–æ²¡æœ‰å…³é”®è¯ï¼Œè®¤ä¸ºåŒ¹é…ï¼ˆé¿å…è¿‡åº¦ä¸¥æ ¼ï¼‰
    return True


def _verify_psyche_continuity(
    char_name: str,
    current_psyche: str,
    prev_psyche: str,
    text: str,
) -> bool:
    """
    éªŒè¯å¿ƒç†çŠ¶æ€æ˜¯å¦ä¸å‰ç« è¿è´¯
    
    Args:
        char_name: è§’è‰²å
        current_psyche: å½“å‰å¿ƒç†çŠ¶æ€
        prev_psyche: å‰ä¸€ç« å¿ƒç†çŠ¶æ€
        text: æ­£æ–‡å†…å®¹
    
    Returns:
        æ˜¯å¦è¿è´¯
    """
    if not current_psyche or not prev_psyche:
        return True  # å¦‚æœä¸ºç©ºï¼Œè®¤ä¸ºè¿è´¯
    
    # æ£€æŸ¥æ­£æ–‡ä¸­æ˜¯å¦æœ‰æ˜ç¡®çš„æƒ…ç»ªçªå˜æè¿°
    mutation_keywords = ["çªç„¶", "ç¬é—´", "çªç„¶", "å¿½ç„¶", "ä¸€ä¸‹å­", "çªç„¶", "çªå˜", "è½¬å˜", "æ”¹å˜"]
    if any(kw in text for kw in mutation_keywords):
        return True  # å¦‚æœæœ‰çªå˜æè¿°ï¼Œè®¤ä¸ºè¿è´¯
    
    # ç®€å•çš„æƒ…ç»ªæ–¹å‘æ£€æŸ¥ï¼ˆä¸è¦æ±‚å®Œå…¨ä¸€è‡´ï¼Œä½†æ–¹å‘åº”è¯¥åˆç†ï¼‰
    # ä¾‹å¦‚ï¼šä»"å¹³é™"åˆ°"æ„¤æ€’"æ˜¯åˆç†çš„ï¼Œä»"æ„¤æ€’"åˆ°"å¹³é™"ä¹Ÿæ˜¯åˆç†çš„
    # ä½†å¦‚æœä»"æåº¦æ„¤æ€’"åˆ°"æåº¦å¿«ä¹"ä¸”æ²¡æœ‰çªå˜æè¿°ï¼Œå¯èƒ½ä¸è¿è´¯
    
    # è¿™é‡Œä½¿ç”¨ç®€å•çš„å¯å‘å¼è§„åˆ™
    # å¦‚æœå¿ƒç†çŠ¶æ€æè¿°å·®å¼‚å¾ˆå¤§ï¼Œä½†æ­£æ–‡ä¸­æ²¡æœ‰çªå˜æè¿°ï¼Œå¯èƒ½ä¸è¿è´¯
    # ä½†ç”±äºæƒ…ç»ªå˜åŒ–æ˜¯å¤æ‚çš„ï¼Œè¿™é‡Œé‡‡ç”¨å®½æ¾ç­–ç•¥
    return True


def _re_extract_psyche_from_text(
    char_name: str,
    text: str,
    prev_psyche: str,
    character_profile: str,
    selected_model: str,
    base_url: Optional[str],
    model_name: Optional[str],
    api_key: Optional[str],
    gemini_base_url: Optional[str],
) -> Optional[str]:
    """
    ä»æ­£æ–‡ä¸­é‡æ–°æå–å¿ƒç†çŠ¶æ€ï¼ˆå½“éªŒè¯å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
    
    Args:
        char_name: è§’è‰²å
        text: æ­£æ–‡å†…å®¹
        prev_psyche: å‰ä¸€ç« å¿ƒç†çŠ¶æ€
        character_profile: è§’è‰²è®¾å®š
        selected_model: æ¨¡å‹ç±»å‹
        base_url: LM Studio base_url
        model_name: æ¨¡å‹åç§°
        api_key: Gemini API Key
        gemini_base_url: Gemini base_url
    
    Returns:
        é‡æ–°æå–çš„å¿ƒç†çŠ¶æ€ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› None
    """
    if not text or not char_name:
        return None
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´çŠ¶æ€åˆ†æå™¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»æ–‡æœ¬ä¸­å‡†ç¡®æå–ç‰¹å®šè§’è‰²çš„å¿ƒç†çŠ¶æ€ã€‚

**é‡è¦çº¦æŸ**ï¼š
1. åªæå–è¯¥è§’è‰²åœ¨æ–‡æœ¬ä¸­çš„å®é™…å¿ƒç†çŠ¶æ€ï¼Œä¸è¦æ¨æµ‹æˆ–æƒ³è±¡
2. å¿…é¡»åŸºäºæ–‡æœ¬ä¸­æ˜ç¡®æè¿°æˆ–æš—ç¤ºçš„å†…å¿ƒæ´»åŠ¨
3. å¦‚æœæ–‡æœ¬ä¸­æ²¡æœ‰è¯¥è§’è‰²çš„å¿ƒç†æè¿°ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
4. å¿ƒç†çŠ¶æ€æè¿°è¦å…·ä½“ï¼Œä¸è¦è¿‡äºç¬¼ç»Ÿ
5. å¿…é¡»ä¸è§’è‰²è®¾å®šç›¸ç¬¦

åªè¿”å›å¿ƒç†çŠ¶æ€æè¿°ï¼Œä¸è¦æ·»åŠ å…¶ä»–æ–‡å­—ã€‚å¦‚æœæ²¡æœ‰ä¿¡æ¯ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ã€‚"""

    user_prompt = f"""è§’è‰²åï¼š{char_name}
è§’è‰²è®¾å®šï¼š{character_profile[:200] if character_profile else "æ— "}
å‰ä¸€ç« å¿ƒç†çŠ¶æ€ï¼š{prev_psyche if prev_psyche else "æ— "}

ã€æ–‡æœ¬ç‰‡æ®µã€‘
{text[:1500]}

è¯·å‡†ç¡®æå–è¯¥è§’è‰²åœ¨å½“å‰æ–‡æœ¬ä¸­çš„å¿ƒç†çŠ¶æ€ã€‚å¦‚æœæ–‡æœ¬ä¸­æ²¡æœ‰è¯¥è§’è‰²çš„å¿ƒç†æè¿°ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ã€‚"""

    try:
        import sys
        
        generate_content_lm_studio = None
        generate_content_gemini = None
        
        possible_module_names = ['app', '__main__']
        
        for module_name in possible_module_names:
            if module_name in sys.modules:
                module = sys.modules[module_name]
                if generate_content_lm_studio is None:
                    generate_content_lm_studio = getattr(module, 'generate_content_lm_studio', None)
                if generate_content_gemini is None:
                    generate_content_gemini = getattr(module, 'generate_content_gemini', None)
                
                if generate_content_lm_studio is not None and generate_content_gemini is not None:
                    break
        
        if generate_content_lm_studio is None or generate_content_gemini is None:
            return None
        
        if selected_model == "gemini":
            if not api_key or not model_name:
                return None
            
            success, result = generate_content_gemini(
                api_key=api_key,
                model_name=model_name,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                base_url=gemini_base_url,
                max_output_tokens=200,
                temperature=0.2,
                stream=False,
            )
            if success and result:
                result = result.strip()
                if result and result != "æ— " and result != "æ— ä¿¡æ¯":
                    return result
        else:
            if not base_url or not model_name:
                return None
            
            success, result = generate_content_lm_studio(
                base_url=base_url,
                model_name=model_name,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                max_tokens=200,
                temperature=0.2,
                stream=False,
            )
            if success and result:
                result = result.strip()
                if result and result != "æ— " and result != "æ— ä¿¡æ¯":
                    return result
    except Exception as e:
        print(f"é‡æ–°æå–å¿ƒç†çŠ¶æ€å¤±è´¥: {e}")
        return None
    
    return None


# ==================== å‘é‡è®¡ç®—æ¨¡å— ====================

# å…¨å±€ Embedding æ¨¡å‹ç¼“å­˜
_embedding_model_cache = None


def get_embedding_model():
    """
    è·å– Embedding æ¨¡å‹ï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    Returns:
        SentenceTransformer æ¨¡å‹æˆ– None
    """
    global _embedding_model_cache
    
    if not EMBEDDING_AVAILABLE or SentenceTransformer is None:
        return None
    
    if _embedding_model_cache is None:
        model_path = ensure_embedding_model_dir(SentenceTransformer)
        if not model_path:
            print("âŒ æ— æ³•åŠ è½½ Embedding æ¨¡å‹ï¼šç¼ºå°‘å¯ç”¨çš„æœ¬åœ°ç›®å½•ï¼Œä¸”è‡ªåŠ¨ä¸‹è½½å¤±è´¥ã€‚")
            return None
        try:
            _embedding_model_cache = SentenceTransformer(model_path, local_files_only=True)
        except Exception as e:
            print(f"åŠ è½½ Embedding æ¨¡å‹å¤±è´¥ï¼š{e}")
            return None
    
    return _embedding_model_cache


def update_vector_state(
    narrative_state: NarrativeState,
    prev_narrative_state: Optional[NarrativeState] = None,
    alpha: float = 0.7
) -> NarrativeState:
    """
    æ›´æ–°çŠ¶æ€å‘é‡ï¼ˆä½¿ç”¨ EMA å¹³æ»‘ç®—æ³•ï¼‰
    
    å°†è§’è‰²çš„"å¿ƒç†çŠ¶æ€"å’Œ"ç”Ÿç†çŠ¶æ€"è½¬åŒ–ä¸ºå‘é‡ï¼Œå¹¶ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡ (EMA) å¹³æ»‘æ›´æ–°ã€‚
    
    å…¬å¼: V_new = Î± Ã— V_current + (1-Î±) Ã— V_history
    
    è¿™æ¨¡æ‹Ÿäº†äººçš„æ€§æ ¼æƒ¯æ€§ï¼Œé˜²æ­¢ AI çªç„¶å‘ç™«ã€‚
    
    Args:
        narrative_state: å½“å‰å™äº‹çŠ¶æ€
        prev_narrative_state: å‰ä¸€ç« çš„å™äº‹çŠ¶æ€ï¼ˆç”¨äº EMA å¹³æ»‘ï¼‰
        alpha: EMA å¹³æ»‘ç³»æ•°ï¼ˆé»˜è®¤ 0.7ï¼ŒèŒƒå›´ 0-1ï¼‰
            - alpha è¶Šå¤§ï¼Œæ–°çŠ¶æ€æƒé‡è¶Šé«˜ï¼ˆå˜åŒ–æ›´å¿«ï¼‰
            - alpha è¶Šå°ï¼Œå†å²çŠ¶æ€æƒé‡è¶Šé«˜ï¼ˆå˜åŒ–æ›´æ…¢ï¼Œæ›´ç¨³å®šï¼‰
    
    Returns:
        æ›´æ–°åçš„ NarrativeStateï¼ˆåŒ…å« character_vectorsï¼‰
    """
    if not NUMPY_AVAILABLE or np is None:
        # å¦‚æœæ²¡æœ‰ numpyï¼Œè¿”å›åŸçŠ¶æ€ï¼ˆä¸è®¡ç®—å‘é‡ï¼‰
        print("âš ï¸ update_vector_state: NUMPY_AVAILABLE ä¸º False æˆ– np ä¸º None")
        return narrative_state
    
    embedding_model = get_embedding_model()
    if embedding_model is None:
        print("âš ï¸ update_vector_state: get_embedding_model() è¿”å› Noneï¼ˆembedding æ¨¡å‹æœªåŠ è½½ï¼‰")
        print(f"   EMBEDDING_AVAILABLE = {EMBEDDING_AVAILABLE}, SentenceTransformer = {SentenceTransformer is not None}")
        return narrative_state
    
    # åˆå§‹åŒ– character_vectorsï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if not hasattr(narrative_state, 'character_vectors') or narrative_state.character_vectors is None:
        narrative_state.character_vectors = {}
    
    print(f"ğŸ” update_vector_state: å¼€å§‹å¤„ç† {len(narrative_state.characters)} ä¸ªè§’è‰²")
    
    # å¯¹æ¯ä¸ªè§’è‰²è®¡ç®—å‘é‡
    for char_name, char_state in narrative_state.characters.items():
        # æ„å»ºçŠ¶æ€æè¿°æ–‡æœ¬
        physique = char_state.get("physique", "")
        psyche = char_state.get("psyche", "")
        focus = char_state.get("focus", "")
        
        # ç»„åˆçŠ¶æ€æè¿°ï¼ˆè‡³å°‘éœ€è¦ physique æˆ– psyche ä¹‹ä¸€ï¼‰
        state_text = f"{physique} {psyche}".strip()
        if focus:
            state_text = f"{state_text} {focus}".strip()
        
        if not state_text:
            # å¦‚æœçŠ¶æ€ä¸ºç©ºï¼Œè·³è¿‡ï¼ˆä½†è®°å½•æ—¥å¿—ï¼‰
            print(f"âš ï¸ è§’è‰² {char_name} çš„çŠ¶æ€ä¸ºç©ºï¼ˆphysique='{physique}', psyche='{psyche}'ï¼‰ï¼Œæ— æ³•ç”Ÿæˆå‘é‡")
            continue
        
        # ç”Ÿæˆå½“å‰çŠ¶æ€çš„å‘é‡
        try:
            current_vector = embedding_model.encode(state_text, convert_to_numpy=True)
            if current_vector is None or len(current_vector) == 0:
                print(f"âš ï¸ è§’è‰² {char_name} çš„å‘é‡ç”Ÿæˆå¤±è´¥ï¼ˆè¿”å›ç©ºå‘é‡ï¼‰")
                continue
            print(f"âœ… è§’è‰² {char_name} çš„å‘é‡ç”ŸæˆæˆåŠŸï¼ˆç»´åº¦ï¼š{len(current_vector)}ï¼‰")
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆè§’è‰² {char_name} çš„å‘é‡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
        
        # EMA å¹³æ»‘ï¼šå¦‚æœæœ‰å†å²å‘é‡ï¼Œè¿›è¡Œå¹³æ»‘
        if prev_narrative_state and prev_narrative_state.character_vectors:
            prev_vector = prev_narrative_state.character_vectors.get(char_name)
            if prev_vector is not None:
                # è½¬æ¢ä¸º numpy æ•°ç»„ï¼ˆå¦‚æœæ˜¯åˆ—è¡¨ï¼‰
                if isinstance(prev_vector, list):
                    prev_vector = np.array(prev_vector)
                
                # EMA å¹³æ»‘: V_new = Î± Ã— V_current + (1-Î±) Ã— V_history
                smoothed_vector = alpha * current_vector + (1 - alpha) * prev_vector
                narrative_state.character_vectors[char_name] = smoothed_vector.tolist()
                print(f"âœ… è§’è‰² {char_name} çš„å‘é‡å·²æ›´æ–°ï¼ˆEMA å¹³æ»‘ï¼‰")
            else:
                # æ²¡æœ‰å†å²å‘é‡ï¼Œç›´æ¥ä½¿ç”¨å½“å‰å‘é‡
                narrative_state.character_vectors[char_name] = current_vector.tolist()
                print(f"âœ… è§’è‰² {char_name} çš„å‘é‡å·²ä¿å­˜ï¼ˆé¦–æ¬¡ç”Ÿæˆï¼‰")
        else:
            # æ²¡æœ‰å†å²çŠ¶æ€ï¼Œç›´æ¥ä½¿ç”¨å½“å‰å‘é‡
            narrative_state.character_vectors[char_name] = current_vector.tolist()
            print(f"âœ… è§’è‰² {char_name} çš„å‘é‡å·²ä¿å­˜ï¼ˆæ— å†å²çŠ¶æ€ï¼‰")
    
    print(f"ğŸ” update_vector_state: å®Œæˆï¼Œå…±ç”Ÿæˆ {len(narrative_state.character_vectors)} ä¸ªè§’è‰²å‘é‡")
    return narrative_state


def get_character_core_vector(
    character_name: str,
    character_description: str,
    embedding_model=None
) -> Optional[np.ndarray]:
    """
    è·å–è§’è‰²çš„æ ¸å¿ƒå‘é‡ï¼ˆåŸºäºè§’è‰²è®¾å®šï¼‰
    
    ç”¨äº OOC æ£€æµ‹ï¼šå°†è§’è‰²è®¾å®šè½¬åŒ–ä¸ºå‘é‡ï¼Œä½œä¸º"äººè®¾åŸºå‡†"ã€‚
    
    Args:
        character_name: è§’è‰²åç§°
        character_description: è§’è‰²è®¾å®šæè¿°
        embedding_model: Embedding æ¨¡å‹ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
    
    Returns:
        è§’è‰²çš„æ ¸å¿ƒå‘é‡ï¼ˆnumpy æ•°ç»„ï¼‰æˆ– None
    """
    if not NUMPY_AVAILABLE or np is None:
        return None
    
    if not character_description or not character_description.strip():
        return None
    
    if embedding_model is None:
        embedding_model = get_embedding_model()
    
    if embedding_model is None:
        return None
    
    try:
        # ç”Ÿæˆè§’è‰²è®¾å®šçš„å‘é‡
        core_vector = embedding_model.encode(character_description, convert_to_numpy=True)
        return core_vector
    except Exception as e:
        print(f"ç”Ÿæˆè§’è‰² {character_name} çš„æ ¸å¿ƒå‘é‡å¤±è´¥: {e}")
        return None


# ==================== NTD å‡çº§ï¼šç« èŠ‚çŠ¶æ€å‘é‡è®¡ç®— ====================

def _compute_chapter_state_vector(
    narrative_state: NarrativeState,
    prev_state: Optional[ChapterNode] = None,
    alpha: float = 0.7
) -> Optional[List[float]]:
    """
    è®¡ç®—ç« èŠ‚æ•´ä½“çŠ¶æ€å‘é‡ï¼ˆNTD å‡çº§ï¼‰
    
    å°† physique + psyche + environment æ‹¼æ¥æˆæè¿°æ–‡æœ¬ï¼Œç„¶åå‘é‡åŒ–ã€‚
    ä½¿ç”¨ EMA å¹³æ»‘ï¼šcurrent_vector = 0.7 * new_vector + 0.3 * prev_vector
    
    Args:
        narrative_state: å½“å‰å™äº‹çŠ¶æ€
        prev_state: å‰ä¸€ç« çš„èŠ‚ç‚¹ï¼ˆç”¨äº EMA å¹³æ»‘ï¼‰
        alpha: EMA å¹³æ»‘ç³»æ•°ï¼ˆé»˜è®¤ 0.7ï¼‰
    
    Returns:
        ç« èŠ‚çŠ¶æ€å‘é‡ï¼ˆ384ç»´åˆ—è¡¨ï¼‰æˆ– None
    """
    if not NUMPY_AVAILABLE or np is None:
        return None
    
    embedding_model = get_embedding_model()
    if embedding_model is None:
        return None
    
    # æ‹¼æ¥çŠ¶æ€æè¿°æ–‡æœ¬
    state_parts = []
    
    # æ”¶é›†æ‰€æœ‰è§’è‰²çš„ physique å’Œ psyche
    for char_name, char_state in narrative_state.characters.items():
        physique = char_state.get("physique", "").strip()
        psyche = char_state.get("psyche", "").strip()
        if physique:
            state_parts.append(f"{char_name}çš„ç”Ÿç†çŠ¶æ€ï¼š{physique}")
        if psyche:
            state_parts.append(f"{char_name}çš„å¿ƒç†çŠ¶æ€ï¼š{psyche}")
    
    # æ·»åŠ ç¯å¢ƒæ°›å›´
    if narrative_state.environment:
        state_parts.append(f"ç¯å¢ƒæ°›å›´ï¼š{narrative_state.environment}")
    
    # å¦‚æœæ²¡æœ‰çŠ¶æ€æè¿°ï¼Œè¿”å› None
    if not state_parts:
        return None
    
    # æ‹¼æ¥æˆå®Œæ•´æè¿°
    state_text = "ã€‚".join(state_parts)
    
    try:
        # ç”Ÿæˆå½“å‰çŠ¶æ€çš„å‘é‡
        new_vector = embedding_model.encode(state_text, convert_to_numpy=True)
        
        # EMA å¹³æ»‘ï¼šå¦‚æœæœ‰å‰ä¸€ç« çš„çŠ¶æ€å‘é‡ï¼Œè¿›è¡Œå¹³æ»‘
        if prev_state and prev_state.state_vector is not None:
            prev_vector = prev_state.state_vector
            # è½¬æ¢ä¸º numpy æ•°ç»„ï¼ˆå¦‚æœæ˜¯åˆ—è¡¨ï¼‰
            if isinstance(prev_vector, list):
                prev_vector = np.array(prev_vector)
            
            # EMA å¹³æ»‘: current_vector = 0.7 * new_vector + 0.3 * prev_vector
            smoothed_vector = alpha * new_vector + (1 - alpha) * prev_vector
            return smoothed_vector.tolist()
        else:
            # æ²¡æœ‰å†å²å‘é‡ï¼Œç›´æ¥ä½¿ç”¨å½“å‰å‘é‡
            return new_vector.tolist()
    
    except Exception as e:
        print(f"è®¡ç®—ç« èŠ‚çŠ¶æ€å‘é‡å¤±è´¥: {e}")
        return None
